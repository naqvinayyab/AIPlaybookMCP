# Building AI Solutions

*This section supports Principles 1, 3, 4, 5, 6, 8, 9, and 10.*

## Building the Team

Like any digital service, developing AI projects requires more than just technology. You need a multidisciplinary team with diverse expertise.

### Minimum Viable AI Team Capabilities

Your team must be able to:
- Identify user needs and accessibility requirements
- Manage and report to stakeholders, collaborate with field experts
- Design, build, test and iterate AI products using agile methodologies
- Ensure responsible development of lawful, ethical, secure and safe-by-design AI services
- Collect, process, store and manage data ethically, safely and securely
- Test with real users and measure service performance
- Support live service running, iteration and retirement

### Essential Team Composition

**Core Roles:**
- **Business leaders and experts**: Understand context and impact on users/services
- **Data scientists**: Understand relevant data, build and train models, conduct testing
- **Software engineers**: Build and integrate solutions
- **User researchers and designers**: Understand user needs, design compelling experiences
- **Legal, commercial and security colleagues**: Ensure safe and responsible AI solutions
- **Ethics and data privacy experts**: Address ethical and privacy considerations

### Team Building Considerations

**Diversity Requirements:**
- Balance between technical and domain expertise
- Include diversity of groups and viewpoints
- Help stay alert to risks of bias and discrimination

**Capability Evolution:**
- Use Government Digital and Data Profession Capability Framework
- Identify skill gaps and forecast workforce needs
- Capability needs change during project lifecycle
- Use Service Manual for role requirements in different phases

**Talent Strategies:**
- Combine new hires, contractors/third parties, internal upskilling
- Address current AI talent shortage
- Consider senior digital secondments
- Internal collaboration with allied professions

## Acquiring Skills and Talent

### Five Groups of Learners

**1. Beginners**
- New to AI, need familiarity with concepts, benefits, limitations, risks
- Focus: Improved understanding of AI

**2. Technical roles outside digital and data**
- Operational delivery and policy professionals using AI for information retrieval, text/image generation
- Focus: Effective and responsible use of AI tools, generative AI limitations, prompt engineering

**3. Data and analytics professionals**
- Varying levels of AI expertise
- Focus: Implementation and use of AI for automated analysis, synthesis, predictive models

**4. Digital professionals**
- Advanced digital skills, likely to develop AI solutions
- Focus: Technical aspects, implementation challenges, AI innovation, collaboration with industry/academia

**5. Leaders**
- Decision makers and senior civil servants
- Focus: Latest AI trends, organizational culture, governance, ethics, strategy impact

### Learning Resources

**Civil Service Learning:**
- Free online AI courses for all civil servants
- AI fundamentals and generative AI
- AI ethics understanding
- Business value of AI
- Overview of main generative AI tools
- Technical curriculum with certificates in different AI fields

**Government Campus:**
- AI courses accessible through learning frameworks

**Digital Excellence Programme:**
- AI course for senior civil servants (grades 6-7)
- For leaders outside digital and data profession

**Additional Training:**
- AI Skills for Business Guidance (DSIT, Innovate UK, Alan Turing Institute)
- Available for business context but helpful for public sector

### Practical Recommendations

- Make full use of training resources including Civil Service Learning
- Build multidisciplinary team with all needed expertise and support
- Use multiple talent acquisition strategies
- Upskill current digital and data professionals
- Provide sandboxes and safe spaces for AI experimentation

## Working Collaboratively

### Internal Collaboration

**Team Relationships:**
- Establish and maintain relationships with stakeholders at varying AI familiarity levels
- Address knowledge and capability gaps through collaboration
- Engage software/technical infrastructure teams early
- Create clear requirements and parameters for solutions

**Cross-Government Engagement:**
- Avoid siloed approaches and work duplication
- Look for cross-government and industry events
- Stay updated on latest developments and best practices
- Join AI community of practice (monthly meetings for public sector AI interest)

### External Collaboration

**Industry and Academia:**
- Work with industry experts and academic institutions
- Foster knowledge exchange and access cutting-edge research
- Leverage external expertise for capability gaps

**Civil Society:**
- Engage with broader civil society
- Understand people's values, concerns, and priorities
- Ensure AI solutions meet public needs
- Include NGOs, underrepresented individuals, groups likely to experience harm

## Defining the Goal

AI is a means to an end, not an objective itself. Be clear on:
- Goals you want to achieve
- User needs
- Where to effectively use AI technologies
- Where to avoid AI entirely

### Potential AI Goals

**Operational Improvements:**
- Automate and streamline processes
- Optimize resource use
- Foster data-driven decision making
- Improve quality and accessibility of services

**Generative AI Specific Goals:**
- Improved public services
- Increased productivity
- Enhanced staff satisfaction
- Cost savings
- Risk reduction

## User Research for AI

User research (UR) is critical to AI project success and provides key insights into human behavior, thinking, and feelings.

### Why UR Matters for AI

- Keeps human in the loop
- Understands human intelligence that AI will replicate/imitate
- Observes how people complete tasks and solve problems
- Uncovers cultural issues impacting AI adoption
- Identifies where and how humans need involvement

### AI-Specific UR Activities

**Understanding if AI is Right Tool:**
- Early UR to observe people in processes
- Help understand user problems and aspirations
- Establish baseline metrics for project outcomes
- Work out appropriate model accuracy levels
- Understand biases in existing human processes

**Defining Performance Metrics:**
- Work with analytical colleagues
- Use research insights to define model and system metrics
- Develop methodologies for measuring ongoing performance

**Preparing Data:**
- Understand what data users use and how they think about activities
- Help find, categorize and summarize training data
- Assist with supervised learning requiring human judgement for labeling
- Consider bias effects on labeling

**Synthesizing Data:**
- Review and assess appropriateness of generated synthetic data
- Develop processes for bringing subject matter experts into loop
- Check UK Statistics Authority guidance on synthetic data ethics

**Evaluating Model Output:**
- Test accuracy and relevance with user samples
- Consider reinforcement learning from human feedback (RLHF)
- Particularly helpful for difficult-to-specify but easy-to-judge tasks

**Measuring Product Usability:**
- Observe user responses to AI system outputs
- Understand if users can confidently complete tasks
- Design testing into AI solution monitoring
- Better understand data drift through user behavior

**Understanding Attitudes:**
- Assess levels of trust and confidence
- Understand how solution is used for decision making
- Distinguish between model metrics (technology performance) and service metrics (user needs/business goals)

### Required UR Skills for AI Projects

- Engage with technology
- Be adaptable in approach
- Design studies with technical and analytical colleagues
- Use attitudinal methods
- Understand change management research
- Design studies to assess user behavior changes over time
- Experience in generative research and concept testing
- Understand privacy and data ethics
- Communicate in non-technical language

### UR Practical Recommendations

- Get user researchers involved from project start
- Design research and evaluation into AI solution support
- Work with user researchers to design continuous assessment methods
- Read GOV.UK Chat case study on UR for AI products

## Identifying Use Cases for AI

Must be led by business and user needs, pain points, and inefficienciesâ€”not technology capabilities.

### Selection Process

**1. Identify Challenges and Opportunities**
- Conduct user research first
- Focus on use cases only solvable by AI or where AI offers significant advantages
- Consider volume, complexity, real-time nature of tasks

**2. Evaluate AI Suitability**
- Advanced pattern detection in large datasets
- Automating complex, dynamic decision-making
- Providing personalization
- Traditional solutions unable to handle requirements

**3. Assess Impact and Feasibility**
- Use cost-benefit analysis
- Consider improvements in efficiency, accuracy, cost reduction
- Assess if necessary skills and infrastructure are available
- Consider training, hiring, or partnering needs

### Use Cases to Avoid

Given AI limitations and ethical/legal implications, avoid:

**Fully Automated Decision Making**
- Be cautious about significant decisions affecting health or safety
- Refer to Human Oversight section for details

**High-Risk or High-Impact Applications**
- AI should not be used alone in areas that could cause harm to health, safety, fundamental rights, or environment
- Follow principles of using AI safely and responsibly

**Other Considerations**
- Check for significant risks related to bias, fairness, transparency, privacy, human rights
- Review existing examples in government applications
- Check Algorithmic Transparency Recording Standard (ATRS) register
- Learn from public sector case studies in appendix

### Practical Recommendations

- Define clear goals consistent with organizational AI roadmap
- Select use cases meeting clear needs fitting AI capabilities
- Research other government organization use cases
- Understand AI limitations and avoid high-risk applications
- Consider principles of safe and responsible AI use

## Creating the AI Support Structure

Ensure organization adopts AI smoothly by considering how AI changes people and processes.

### Essential Structures

**AI Strategy and Adoption Plan**
- Clear statement of AI use within organization
- Impact on existing organizational structures
- Change management plans

**AI Principles**
- Simple top-level principles embodying values and goals
- Followable by all people building solutions

**AI Governance Board**
- Senior leaders and experts group
- Set principles and review/authorize AI uses

**AI Communication Strategy**
- Approach for engaging internal and external stakeholders
- Gain support, share best practice, show transparency

**AI Sourcing and Partnership Strategy**
- Define which capabilities to build internally
- Which to seek from partners

**AI Training**
- Resources for team upskilling
- Based on learning needs analysis

### Additional Considerations

**Change Management Team**
- Small team with senior leadership access
- Shape organizational approach

**Use Cases Register**
- Capture use cases and prioritize exploration

**Monitoring Systems**
- Gather feedback and quickly identify emerging risks
- Duration of system lifecycle

**Review and Change Processes**
- Provide staff sufficient time, information, tools
- Identify and adapt to emerging risks during change

**Fallback Processes**
- Ensure critical functionality maintained if changes must be reverted
- AI system termination procedures

### Practical Recommendations

- Identify support structures needed for AI maturity and adoption level
- Reuse existing support structures for other technologies where possible
- Design appropriate method for capturing and prioritizing opportunities
- Develop communication strategy for engaging leaders and staff
- Demonstrate activity and reduce resistance to change

---

**Next:** [Buying AI](./04_buying_ai.md)